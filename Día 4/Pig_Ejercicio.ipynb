{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pig_Ejercicio.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWPNm5pWIVfq"
      },
      "source": [
        "\n",
        "# 1. Preliminares\n",
        "\n",
        "1.   Cargar el contenedor.\n",
        "\n",
        " `docker run --rm -it -v C:\\cerdito:/datalake -p 8088:8088 jdvelasq/pig:0.17.0-pseudo`\n",
        "\n",
        "2.   Obtiene los datos, puedes tenerlos en la carpeta compartida o descargarlos con wget. Requerimos el archivo peliculas.txt\n",
        "\n",
        "3. Verifica que tienes los archivos en el ambiente local del contenedor con el comando \n",
        "`root@algo:/datalake# ls`\n",
        "\n",
        "4. Ahora verifica que archivos tienes en el sistema de archivos hadoop. \n",
        "`\n",
        "root@algo:/datalake# hadoop fs -ls\n",
        "`\n",
        "\n",
        "5. Ahora los datos locales en el sistema de archivos Hadoop\n",
        "`root@algo:/datalake# hadoop fs -put peliculas.txt`\n",
        "\n",
        "6. Vuelve a verificar que tienes en el sistema de archivos de Hadoop.\n",
        "\n",
        "```\n",
        "root@algo:/datalake# hadoop fs -ls\n",
        "\n",
        "Found 1 items\n",
        "-rw-r--r--   1 root supergroup        348 2021-04-17 00:11 peliculas.txt\n",
        "```\n",
        "\n",
        "7. Consultemos las dos primeras líneas del archivo que se ha cargado en el sistema de archivos de Hadoop, se combina con el comando `head` de bash.\n",
        "\n",
        "`root@algo:/datalake# hadoop fs -cat peliculas.txt | head -n 2`\n",
        "\n",
        "* Recuerda para consultar lo mismo de manera local es con:\n",
        "`root@algo:/datalake# head -n 2 peliculas.txt`\n",
        "\n",
        "* Consultar tamaño en disco: `root@algo:/datalake# hadoop fs -df -h` \n",
        "\n",
        "* Consultar el último kb de información de un archivo\n",
        "`root@algo:/datalake# hadoop -tail peliculas.txt` \n",
        "\n",
        "\n",
        "8. Ejecutamos PIG con el comando `pig` prestar atención al Command Prompt o Símbolo del Sistema, en este caso `grunt>`\n",
        "```\n",
        "root@f3a874f91b1b:/datalake# pig\n",
        "2021-04-17 00:14:15,156 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
        "grunt> \n",
        "```\n",
        "Ahora pig está a tus órdenes para recibir comandos. Podemos salir de pig escribiendo el comando `quit.\n",
        "\n",
        "* Observación: Podemos usar comandos hadoop dentro de pig, por ejemplo, consultar el tamaño en disco: `grunt> fs -df -h`\n",
        "\n",
        "10. Pig, en modo pseudo (distribuído), trabaja con los archivos almacenados en el sistema de archivos Hadoop. \n",
        "\n",
        "`misPelis = LOAD 'peliculas.txt' USING PigStorage(',') as (id,nombre,ano,calificacion,duracion);`\n",
        "\n",
        "* Debes siempre cerrar o terminar un comando con punto y coma (;) en caso de no hacerlo te aparecerá el siguiente simbolo`>>` \n",
        "\n",
        "11. Consultemos el contenido de la bolsa (bag). Los nombres de bolsas son sensibles a las mayúsculas. `grunt> dump misPelis;`\n",
        "\n",
        "12. Consultar la estructura de la bolsa. `grunt> describe misPelis;`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4pv8XhBj8Os"
      },
      "source": [
        "# 2. Consultas - Filtrado (FILTER) - haciendo casting\n",
        "\n",
        "Recuerda las consultas se ejecutan en `grunt>`\n",
        "\n",
        "¿Notas algo raro en la estructura de la bosa? `grunt> describe misPelis;`\n",
        "\n",
        "1. Consutar las peliculas con una calificación mayor a 4.1\n",
        "\n",
        "`misPelisC1 = FILTER misPelis BY (float)calificacion > 4.1;`\n",
        "\n",
        "`DUMP misPelisC1; --muestra la bolsa`\n",
        "\n",
        "2. Almacenar la consulta en disco HDSF (Hadoop)fs: \n",
        "\n",
        "`STORE misPelisC1 into 'lasMejoresPelis';`\n",
        "\n",
        "Alternativa indicando el separador: `STORE misPelisC1 INTO 'lasMejoresPelis' USING PigStorage(';');`\n",
        "\n",
        "Contenido de la carpeta creada: `fs -ls lasMejoresPelis`\n",
        "\n",
        "Contenido del archivo que contiene los resultados: `fs -cat lasMejoresPelis/part-m-00000`\n",
        "\n",
        "Copiamos el archivo en la carpeta local:`fs -copyToLocal lasMejoresPelis/part-m-00000`\n",
        "\n",
        "También se puede copiar toda la carpeta en la carpeta local:`fs -copyToLocal lasMejoresPelis`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCmMzXa_jrcs"
      },
      "source": [
        "# 3. Cargar datos con tipado y filtrado (FILTER).\n",
        "\n",
        "1. Definir el tipo de datos durante la carga:\n",
        "\n",
        "`grunt> misPelisData = LOAD 'peliculas.txt' USING PigStorage(',') as (id:int,nombre:chararray,ano:int,calificacion:double,duracion:int);`\n",
        "\n",
        "Verificamos que cargaron: `dump misPelisData;`\n",
        "\n",
        "Verificamos la estructura de la bolsa: `describe misPelisData;`\n",
        "\n",
        "* ¿Qué sucede si se realiza un cambio en el archivo local de datos y deseo reflejarlos en la bolsa?\n",
        "\n",
        "2. Consultar las peliculas entre 1990 y 1998\n",
        "\n",
        "`pelisViejas = FILTER misPelisData by ano > 1989 and ano < 1995;`\n",
        "\n",
        "`dump pelisViejas;`\n",
        "\n",
        "3. Peliculas que comienzan por la letra L\n",
        "\n",
        "`pelisL = FILTER misPelisData by nombre matches 'L.*';`\n",
        "\n",
        "`dump pelisL;`\n",
        "\n",
        "4. Peliculas con una duración de más de dos horas (7200 segundos)\n",
        "\n",
        "`largometrajes = FILTER misPelisData by duracion >= 7200;`\n",
        "\n",
        "`dump largometrajes;`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og0PMzdA1T3T"
      },
      "source": [
        "# 4. Transformación de columnas (FOREACH)\n",
        "\n",
        "`duracionHoras = FOREACH misPelisData GENERATE nombre, (double)(duracion/3600);`\n",
        "\n",
        "`dump duracionHoras;`\n",
        "\n",
        "El resultado genera números enteros, porque división de enteros es resultado entero.\n",
        "\n",
        "`duracionHoras = FOREACH misPelisData GENERATE nombre, (double)duracion/3600;`\n",
        "\n",
        "`dump duracionHoras;`\n",
        "\n",
        "Ahora redondeamos a dos cifras decimales;\n",
        "\n",
        "`duracionHoras = FOREACH misPelisData GENERATE nombre, ROUND_TO((double)duracion/3600, 2);`\n",
        "\n",
        "`dump duracionHoras;`\n",
        "\n",
        "***Ejercicio***, almacena este resultado en el disco local.\n",
        "\n",
        "[Ver más funciones de pig](https://www.tutorialspoint.com/apache_pig/apache_pig_math_functions.htm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l68Z5tOEABhG"
      },
      "source": [
        "# 5. Agrupaciones (GROUP)\n",
        "\n",
        "1. Agrupamos las tupas \"registros\" por año de la pelicula.\n",
        "\n",
        "`gPorAno = GROUP misPelisData by ano;`\n",
        "\n",
        "`DUMP gPorAno;`\n",
        "\n",
        "2. Cantidad de Peliculas por año.\n",
        "\n",
        "`conteoPorAno = FOREACH gPorAno GENERATE group, COUNT(misPelisData)`\n",
        "\n",
        "`dump conteoPorAno;`\n",
        "\n",
        "***Ejercicio***: Contar la cantidad de películas por año antes de 1995."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZrioM7ZCcPJ"
      },
      "source": [
        "# 6. Ordenamiento ORDER y LIMIT\n",
        "\n",
        "Ordenar descendentemente las peliculas por año.\n",
        "\n",
        "`ordenDesc = ORDER misPelisData by ano DESC;`\n",
        "\n",
        "`dump ordenDesc;`\n",
        "\n",
        "*   Se ordena ascendentemente con `ASC`\n",
        "\n",
        "Ahora mostramos los 3 primeros peliculas ordenadas por año descendentemente.\n",
        "\n",
        "`misTres = LIMIT ordenDesc 3;`\n",
        "\n",
        "`dump misTres;`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50CkwMP6RSoS"
      },
      "source": [
        "# Recomendados\n",
        "\n",
        "\n",
        "[Wikitechy](https://www.wikitechy.com/tutorials/apache-pig/apache-pig-example)\n",
        "\n",
        "[Tutorialspoint](https://www.tutorialspoint.com/apache_pig/apache_pig_architecture.htm)"
      ]
    }
  ]
}